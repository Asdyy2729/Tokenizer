# Tokenizer
This is a Tokenizer build for a basic higher level understanding how LLMS creates(encode) tokens by thier way of mapping what 1 token is like and Decode from tokens to sentences.
